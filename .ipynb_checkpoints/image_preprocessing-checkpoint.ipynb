{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d351ca8",
   "metadata": {},
   "source": [
    "# convert JPG to numbers\n",
    "- https://www.kdnuggets.com/2020/01/convert-picture-numbers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622bbed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A reliable way to read images into Python is with Pillow, \n",
    "# an actively maintained fork of the classic Python Image Library or PIL, and Numpy.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17face97",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(Image.open(\"../input/forbidden_city.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89df1a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[102, 188, 239],\n",
       "        [102, 188, 239],\n",
       "        [102, 188, 239],\n",
       "        ...,\n",
       "        [133, 213, 248],\n",
       "        [133, 213, 248],\n",
       "        [133, 213, 248]],\n",
       "\n",
       "       [[102, 188, 239],\n",
       "        [102, 188, 239],\n",
       "        [102, 188, 239],\n",
       "        ...,\n",
       "        [135, 215, 250],\n",
       "        [135, 215, 250],\n",
       "        [135, 215, 250]],\n",
       "\n",
       "       [[105, 188, 240],\n",
       "        [105, 188, 240],\n",
       "        [105, 188, 240],\n",
       "        ...,\n",
       "        [137, 215, 251],\n",
       "        [137, 215, 251],\n",
       "        [137, 215, 251]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[133, 135, 134],\n",
       "        [128, 132, 131],\n",
       "        [124, 130, 128],\n",
       "        ...,\n",
       "        [114, 124, 125],\n",
       "        [114, 124, 125],\n",
       "        [116, 126, 127]],\n",
       "\n",
       "       [[ 47,  32,  29],\n",
       "        [ 42,  31,  27],\n",
       "        [ 36,  31,  25],\n",
       "        ...,\n",
       "        [117, 123, 121],\n",
       "        [113, 119, 117],\n",
       "        [113, 119, 117]],\n",
       "\n",
       "       [[148, 118, 108],\n",
       "        [142, 118, 106],\n",
       "        [136, 120, 105],\n",
       "        ...,\n",
       "        [127, 129, 126],\n",
       "        [118, 120, 117],\n",
       "        [112, 114, 111]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When reading in a color image, the resulting object img is a three-dimensional Numpy array. \n",
    "# The data type is often numpy.uint8, which is a natural and efficient way to represent \n",
    "# color levels between 0 and 255\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4480598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to facilitate calculations, \n",
    "# it is the most convenient to convert the image values to floats between 0 and 1. \n",
    "# In python3, the easiest way to do this is to divide by 255: img *= 1/255\n",
    "\n",
    "\n",
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "286ce5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4       , 0.7372549 , 0.9372549 ],\n",
       "        [0.4       , 0.7372549 , 0.9372549 ],\n",
       "        [0.4       , 0.7372549 , 0.9372549 ],\n",
       "        ...,\n",
       "        [0.52156863, 0.83529412, 0.97254902],\n",
       "        [0.52156863, 0.83529412, 0.97254902],\n",
       "        [0.52156863, 0.83529412, 0.97254902]],\n",
       "\n",
       "       [[0.4       , 0.7372549 , 0.9372549 ],\n",
       "        [0.4       , 0.7372549 , 0.9372549 ],\n",
       "        [0.4       , 0.7372549 , 0.9372549 ],\n",
       "        ...,\n",
       "        [0.52941176, 0.84313725, 0.98039216],\n",
       "        [0.52941176, 0.84313725, 0.98039216],\n",
       "        [0.52941176, 0.84313725, 0.98039216]],\n",
       "\n",
       "       [[0.41176471, 0.7372549 , 0.94117647],\n",
       "        [0.41176471, 0.7372549 , 0.94117647],\n",
       "        [0.41176471, 0.7372549 , 0.94117647],\n",
       "        ...,\n",
       "        [0.5372549 , 0.84313725, 0.98431373],\n",
       "        [0.5372549 , 0.84313725, 0.98431373],\n",
       "        [0.5372549 , 0.84313725, 0.98431373]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.52156863, 0.52941176, 0.5254902 ],\n",
       "        [0.50196078, 0.51764706, 0.51372549],\n",
       "        [0.48627451, 0.50980392, 0.50196078],\n",
       "        ...,\n",
       "        [0.44705882, 0.48627451, 0.49019608],\n",
       "        [0.44705882, 0.48627451, 0.49019608],\n",
       "        [0.45490196, 0.49411765, 0.49803922]],\n",
       "\n",
       "       [[0.18431373, 0.1254902 , 0.11372549],\n",
       "        [0.16470588, 0.12156863, 0.10588235],\n",
       "        [0.14117647, 0.12156863, 0.09803922],\n",
       "        ...,\n",
       "        [0.45882353, 0.48235294, 0.4745098 ],\n",
       "        [0.44313725, 0.46666667, 0.45882353],\n",
       "        [0.44313725, 0.46666667, 0.45882353]],\n",
       "\n",
       "       [[0.58039216, 0.4627451 , 0.42352941],\n",
       "        [0.55686275, 0.4627451 , 0.41568627],\n",
       "        [0.53333333, 0.47058824, 0.41176471],\n",
       "        ...,\n",
       "        [0.49803922, 0.50588235, 0.49411765],\n",
       "        [0.4627451 , 0.47058824, 0.45882353],\n",
       "        [0.43921569, 0.44705882, 0.43529412]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc52095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f0395bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d1774e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.669886786253653"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5456cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 612, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d156c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
